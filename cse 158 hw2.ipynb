{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7a46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip \n",
    "import pandas as pd\n",
    "import math \n",
    "import random \n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787c3c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'goodreads_reviews_comics_graphic.json')\n",
    "with open(fp) as file:\n",
    "    data = file.readlines()\n",
    "    data = list(map(json.loads, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5663a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "ratingDict = {}\n",
    "for i in range(0, len(data)):\n",
    "    user = data[i]['user_id']\n",
    "    item = data[i]['book_id']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    ratingDict[(user,item)] = data[i]['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3b2da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "userAverages = {}\n",
    "itemAverages = {}\n",
    "\n",
    "for u in itemsPerUser:\n",
    "    rs = [ratingDict[(u,i)] for i in itemsPerUser[u]]\n",
    "    userAverages[u] = sum(rs) / len(rs)\n",
    "    \n",
    "for i in usersPerItem:\n",
    "    rs = [ratingDict[(u,i)] for u in usersPerItem[i]]\n",
    "    itemAverages[i] = sum(rs) / len(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be7f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "867964f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(i, N):\n",
    "    similarities = []\n",
    "    users = usersPerItem[i]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == i: continue\n",
    "        sim = Jaccard(users, usersPerItem[i2])\n",
    "        #sim = Pearson(i, i2) # Could use alternate similarity metrics straightforwardly\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4116431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.16666666666666666, '25334626'),\n",
       " (0.14285714285714285, '25659811'),\n",
       " (0.13793103448275862, '18369278'),\n",
       " (0.13157894736842105, '18430205'),\n",
       " (0.12903225806451613, '20299669'),\n",
       " (0.125, '17995154'),\n",
       " (0.12121212121212122, '23241671'),\n",
       " (0.12121212121212122, '23093378'),\n",
       " (0.12121212121212122, '18853527'),\n",
       " (0.11764705882352941, '26778333')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#QUESTION 1\n",
    "query = data[0]['book_id']\n",
    "ms = mostSimilar(query, 10)\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4175971a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.16666666666666666, '25334626'),\n",
       " (0.14285714285714285, '25659811'),\n",
       " (0.13793103448275862, '18369278'),\n",
       " (0.13157894736842105, '18430205'),\n",
       " (0.12903225806451613, '20299669'),\n",
       " (0.125, '17995154'),\n",
       " (0.12121212121212122, '23241671'),\n",
       " (0.12121212121212122, '23093378'),\n",
       " (0.12121212121212122, '18853527'),\n",
       " (0.11764705882352941, '26778333')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#QUESTION 2 PART A\n",
    "results_indices = []\n",
    "for i in range(0, len(data)):\n",
    "    if data[i]['user_id'] == data[0]['user_id']:\n",
    "        results_indices.append(i)\n",
    "\n",
    "results_dict = {}\n",
    "for i in range(0, len(results_indices)):\n",
    "    results_dict[i] = data[results_indices[i]]['rating']\n",
    "    \n",
    "sorted_dict = sorted(results_dict.items(), key = lambda x:x[1], reverse = True)\n",
    "highest_rated_index = sorted_dict[0][0]\n",
    "\n",
    "query = data[highest_rated_index]['book_id']\n",
    "ms = mostSimilar(query, 10)\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17f34647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3333333333333333, '10767466'),\n",
       " (0.25, '17570797'),\n",
       " (0.2, '15704307'),\n",
       " (0.14285714285714285, '10138607'),\n",
       " (0.05555555555555555, '12434747'),\n",
       " (0.030303030303030304, '17995248'),\n",
       " (0.023809523809523808, '10105459'),\n",
       " (0.02040816326530612, '10997645'),\n",
       " (0.014925373134328358, '10361139'),\n",
       " (0.0136986301369863, '10264328')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#QUESTION 2 PART B\n",
    "df = pd.DataFrame(data)\n",
    "df = df[['user_id','book_id','rating']]\n",
    "\n",
    "def mostSimilarUsers(j, N):\n",
    "    similarities = []\n",
    "    itemsReturned = []\n",
    "    items = itemsPerUser[j]\n",
    "    for j2 in itemsPerUser:\n",
    "        if j2 == j: continue\n",
    "        sim = Jaccard(items, itemsPerUser[j2])\n",
    "        #sim = Pearson(i, i2) # Could use alternate similarity metrics straightforwardly\n",
    "        similarities.append((sim,j2))\n",
    "    similarities.sort(reverse=True)\n",
    "    for i in similarities:\n",
    "        filtered = df[df['user_id'] == i[1]]\n",
    "        filtered = filtered.sort_values(by = 'rating', ascending = False).reset_index()\n",
    "        highest_rating = filtered.iloc[0]['rating']\n",
    "        filtered = filtered[filtered['rating'] == highest_rating]\n",
    "        if filtered.shape[0] == 1:\n",
    "            book_retrieved = filtered.iloc[filtered.shape[0]-1]['book_id']\n",
    "        else:\n",
    "            book_retrieved = filtered['book_id'].min()\n",
    "        if j in usersPerItem[book_retrieved]:\n",
    "            continue\n",
    "        elif len(itemsReturned) < N:\n",
    "            itemsReturned.append((i[0], book_retrieved))\n",
    "        else:\n",
    "            break\n",
    "    return itemsReturned\n",
    "\n",
    "query = data[0]['user_id']\n",
    "ms = mostSimilarUsers(query, 10)\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd47d06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0000000000000002, '95402'),\n",
       " (1.0000000000000002, '9517'),\n",
       " (1.0000000000000002, '9516'),\n",
       " (1.0000000000000002, '9408670'),\n",
       " (1.0000000000000002, '8891233'),\n",
       " (1.0000000000000002, '8714027'),\n",
       " (1.0000000000000002, '838933'),\n",
       " (1.0000000000000002, '790192'),\n",
       " (1.0000000000000002, '72114'),\n",
       " (1.0000000000000002, '6779672')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#QUESTION 3 PART A\n",
    "def Pearson(i1, i2):\n",
    "    # Between two items\n",
    "    iBar1 = itemAverages[i1]\n",
    "    iBar2 = itemAverages[i2]\n",
    "    inter = usersPerItem[i1].intersection(usersPerItem[i2])\n",
    "    numer = 0\n",
    "    denom1 = 0\n",
    "    denom2 = 0\n",
    "    denom = 0\n",
    "    for u in inter:\n",
    "        numer += (ratingDict[(u,i1)] - iBar1)*(ratingDict[(u,i2)] - iBar2)\n",
    "    for u in inter: #usersPerItem[i1]:\n",
    "        denom1 += (ratingDict[(u,i1)] - iBar1)**2\n",
    "    #for u in usersPerItem[i2]:\n",
    "        denom2 += (ratingDict[(u,i2)] - iBar2)**2\n",
    "        denom += denom1 * denom2\n",
    "    denom = (denom) **(1/2)\n",
    "    if denom == 0: return 0\n",
    "    return numer / denom\n",
    "\n",
    "def nsimilarPearson(i, N):\n",
    "    similarities = []\n",
    "    #users = usersPerItem[i]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == i: continue\n",
    "        #sim = J(users, usersPerItem[i2])\n",
    "        sim = Pearson(i, i2) # Could use alternate similarity metrics straightforwardly\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:N]\n",
    "\n",
    "query = data[0]['book_id']\n",
    "ms = nsimilarPearson(query, 10)\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "718f23a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.31898549007874194, '20300526'),\n",
       " (0.1878586543136926, '13280885'),\n",
       " (0.17896391275176457, '18208501'),\n",
       " (0.16269036695641687, '25430791'),\n",
       " (0.16269036695641687, '21521612'),\n",
       " (0.1555075595594449, '1341758'),\n",
       " (0.1526351566298752, '6314737'),\n",
       " (0.1520488804816035, '4009034'),\n",
       " (0.1494406444160154, '988744'),\n",
       " (0.14632419481281994, '18430205')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#QUESTION 3 PART B\n",
    "def Pearson2(i1, i2):\n",
    "    # Between two items\n",
    "    iBar1 = itemAverages[i1]\n",
    "    iBar2 = itemAverages[i2]\n",
    "    inter = usersPerItem[i1].intersection(usersPerItem[i2])\n",
    "    numer = 0\n",
    "    denom1 = 0\n",
    "    denom2 = 0\n",
    "    for u in inter:\n",
    "        numer += (ratingDict[(u,i1)] - iBar1)*(ratingDict[(u,i2)] - iBar2)\n",
    "    for u in usersPerItem[i1]:\n",
    "        denom1 += (ratingDict[(u,i1)] - iBar1)**2\n",
    "    for u in usersPerItem[i2]:\n",
    "        denom2 += (ratingDict[(u,i2)] - iBar2)**2\n",
    "    denom = (denom1 * denom2) **(1/2)\n",
    "    if denom == 0: return 0\n",
    "    return numer / denom\n",
    "\n",
    "def nsimilarPearson2(i, N):\n",
    "    similarities = []\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == i: continue\n",
    "        #sim = J(users, usersPerItem[i2])\n",
    "        sim = Pearson2(i, i2) # Could use alternate similarity metrics straightforwardly\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:N]\n",
    "\n",
    "query = data[0]['book_id']\n",
    "ms = nsimilarPearson2(query, 10)\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da5bbf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7123545753840687"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#QUESTION 4 \n",
    "ratingMean = df['rating'].mean()\n",
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for i2 in itemsPerUser[user]:\n",
    "        if i2 == item: continue\n",
    "        ratings.append(ratingDict[(user, i2)]-itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return ratingMean\n",
    "    \n",
    "predictions = []\n",
    "for i in range(0, 10000):\n",
    "    predictions.append(predictRating(data[i]['user_id'], data[i]['book_id']))\n",
    "    \n",
    "MSE = sum((df['rating'][0:10000]-predictions)**2)/10000\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b4d3b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7107374206362199"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#QUESTION 5 PART A\n",
    "def Cosine(i1, i2):\n",
    "    # Between two items\n",
    "    inter = usersPerItem[i1].intersection(usersPerItem[i2])\n",
    "    numer = 0\n",
    "    denom1 = 0\n",
    "    denom2 = 0\n",
    "    for u in inter:\n",
    "        numer += ratingDict[(u,i1)]*ratingDict[(u,i2)]\n",
    "    for u in usersPerItem[i1]:\n",
    "        denom1 += ratingDict[(u,i1)]**2\n",
    "    for u in usersPerItem[i2]:\n",
    "        denom2 += ratingDict[(u,i2)]**2\n",
    "    denom = math.sqrt(denom1) * math.sqrt(denom2)\n",
    "    if denom == 0: return 0\n",
    "    return numer / denom\n",
    "\n",
    "def predictRatingcosine(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for i2 in itemsPerUser[user]:\n",
    "        if i2 == item: continue\n",
    "        ratings.append(ratingDict[(user, i2)]-itemAverages[i2])\n",
    "        similarities.append(Cosine(item, i2))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return ratingMean\n",
    "\n",
    "predictions = []\n",
    "for i in range(0, 10000):\n",
    "    predictions.append(predictRatingcosine(data[i]['user_id'], data[i]['book_id']))\n",
    "    \n",
    "MSE = sum((df['rating'][0:10000]-predictions)**2)/10000\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c64d1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.90067629086688e+29"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#QUESTION 5 PART B PEARSON1\n",
    "def predictRatingpearson1(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for i2 in itemsPerUser[user]:\n",
    "        if i2 == item: continue\n",
    "        ratings.append(ratingDict[(user, i2)]-itemAverages[i2])\n",
    "        similarities.append(Pearson(item, i2))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return ratingMean\n",
    "    \n",
    "predictions = []\n",
    "for i in range(0, 10000):\n",
    "    predictions.append(predictRatingpearson1(data[i]['user_id'], data[i]['book_id']))\n",
    "    \n",
    "MSE = sum((df['rating'][0:10000]-predictions)**2)/10000\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5e44cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9602.52533754106"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5 Part B Pearson2\n",
    "def predictRatingpearson2(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for i2 in itemsPerUser[user]:\n",
    "        if i2 == item: continue\n",
    "        ratings.append(ratingDict[(user, i2)]-itemAverages[i2])\n",
    "        similarities.append(Pearson2(item, i2))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return ratingMean\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for i in range(0, 10000):\n",
    "    predictions.append(predictRatingpearson2(data[i]['user_id'], data[i]['book_id']))\n",
    "\n",
    "MSE = sum((df['rating'][0:10000]-predictions)**2)/10000\n",
    "MSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
